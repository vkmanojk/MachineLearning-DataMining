{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import zipfile\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "from collections import defaultdict\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import syft as sy\n",
    "from syft.frameworks.torch.fl import utils\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)\n",
    "RANDOM_STATE = 1\n",
    "set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "rating_file = data_dir + 'ratings.dat' \n",
    "user_file = data_dir + 'users.dat'\n",
    "movie_file = data_dir + 'movies.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv(rating_file, sep='::', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "df_user = pd.read_csv(user_file, sep='::', header=None, names=['user_id', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "df_movie = pd.read_csv(movie_file, sep='::', header=None, names=['movie_id', 'title', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_dict = {\n",
    "    1:  \"Under 18\",\n",
    "    18:  \"18-24\",\n",
    "    25:  \"25-34\",\n",
    "    35:  \"35-44\",\n",
    "    45:  \"45-49\",\n",
    "    50:  \"50-55\",\n",
    "    56:  \"56+\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_dict = {\n",
    "    0:  \"other or not specified\",\n",
    "    1:  \"academic/educator\",\n",
    "    2:  \"artist\",\n",
    "    3:  \"clerical/admin\",\n",
    "    4:  \"college/grad student\",\n",
    "    5:  \"customer service\",\n",
    "    6:  \"doctor/health care\",\n",
    "    7:  \"executive/managerial\",\n",
    "    8:  \"farmer\",\n",
    "    9:  \"homemaker\",\n",
    "    10:  \"K-12 student\",\n",
    "    11:  \"lawyer\",\n",
    "    12:  \"programmer\",\n",
    "    13:  \"retired\",\n",
    "    14:  \"sales/marketing\",\n",
    "    15:  \"scientist\",\n",
    "    16:  \"self-employed\",\n",
    "    17:  \"technician/engineer\",\n",
    "    18:  \"tradesman/craftsman\",\n",
    "    19:  \"unemployed\",\n",
    "    20:  \"writer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp  \\\n",
       "0        1      1193       5  978300760   \n",
       "1        1       661       3  978302109   \n",
       "2        1       914       3  978301968   \n",
       "3        1      3408       4  978300275   \n",
       "4        1      2355       5  978824291   \n",
       "\n",
       "                                    title                         genre  \\\n",
       "0  One Flew Over the Cuckoo's Nest (1975)                         Drama   \n",
       "1        James and the Giant Peach (1996)  Animation|Children's|Musical   \n",
       "2                     My Fair Lady (1964)               Musical|Romance   \n",
       "3                  Erin Brockovich (2000)                         Drama   \n",
       "4                    Bug's Life, A (1998)   Animation|Children's|Comedy   \n",
       "\n",
       "  gender  age  occupation zipcode  \n",
       "0      F    1          10   48067  \n",
       "1      F    1          10   48067  \n",
       "2      F    1          10   48067  \n",
       "3      F    1          10   48067  \n",
       "4      F    1          10   48067  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_rating.merge(df_movie, left_on='movie_id', right_on='movie_id', how='left')\n",
    "df = df_temp.merge(df_user, left_on='user_id', right_on='user_id', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_preview(ratings, n=15):\n",
    "    \n",
    "    user_groups = ratings.groupby('user_id')['rating'].count()\n",
    "    top_users = user_groups.sort_values(ascending=False)[:15]\n",
    "\n",
    "    movie_groups = ratings.groupby('movie_id')['rating'].count()\n",
    "    top_movies = movie_groups.sort_values(ascending=False)[:15]\n",
    "\n",
    "    top = (\n",
    "        ratings.\n",
    "        join(top_users, rsuffix='_r', how='inner', on='user_id').\n",
    "        join(top_movies, rsuffix='_r', how='inner', on='movie_id'))\n",
    "\n",
    "    return pd.crosstab(top.user_id, top.movie_id, top.rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>110</th>\n",
       "      <th>260</th>\n",
       "      <th>480</th>\n",
       "      <th>589</th>\n",
       "      <th>593</th>\n",
       "      <th>608</th>\n",
       "      <th>1196</th>\n",
       "      <th>1198</th>\n",
       "      <th>1210</th>\n",
       "      <th>1270</th>\n",
       "      <th>1580</th>\n",
       "      <th>2028</th>\n",
       "      <th>2571</th>\n",
       "      <th>2762</th>\n",
       "      <th>2858</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  110   260   480   589   593   608   1196  1198  1210  1270  1580  \\\n",
       "user_id                                                                      \n",
       "889        4.0   4.0   3.0   5.0   5.0   4.0   4.0   NaN   3.0   4.0   3.0   \n",
       "1015       4.0   5.0   4.0   5.0   5.0   5.0   4.0   5.0   4.0   4.0   4.0   \n",
       "1150       2.0   5.0   NaN   2.0   3.0   5.0   4.0   2.0   3.0   2.0   2.0   \n",
       "1181       3.0   4.0   2.0   5.0   3.0   3.0   4.0   3.0   3.0   3.0   4.0   \n",
       "1449       3.0   3.0   2.0   2.0   5.0   5.0   3.0   4.0   2.0   2.0   4.0   \n",
       "1680       1.0   2.0   5.0   5.0   5.0   5.0   5.0   5.0   3.0   3.0   4.0   \n",
       "1941       5.0   5.0   5.0   3.0   5.0   4.0   5.0   5.0   5.0   5.0   5.0   \n",
       "1980       4.0   4.0   4.0   4.0   5.0   5.0   4.0   5.0   4.0   5.0   4.0   \n",
       "2063       5.0   4.0   4.0   2.0   5.0   2.0   4.0   4.0   4.0   4.0   3.0   \n",
       "2909       5.0   5.0   5.0   4.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   \n",
       "3618       3.0   4.0   4.0   3.0   5.0   4.0   3.0   4.0   3.0   4.0   3.0   \n",
       "4169       4.0   5.0   5.0   4.0   5.0   5.0   5.0   5.0   5.0   4.0   4.0   \n",
       "4277       5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   4.0   5.0   4.0   \n",
       "4344       5.0   5.0   4.0   4.0   2.0   5.0   5.0   5.0   5.0   4.0   3.0   \n",
       "5795       5.0   5.0   5.0   4.0   5.0   4.0   5.0   5.0   4.0   5.0   1.0   \n",
       "\n",
       "movie_id  2028  2571  2762  2858  \n",
       "user_id                           \n",
       "889        3.0   5.0   NaN   2.0  \n",
       "1015       5.0   5.0   5.0   4.0  \n",
       "1150       2.0   1.0   2.0   4.0  \n",
       "1181       4.0   5.0   4.0   3.0  \n",
       "1449       3.0   4.0   4.0   4.0  \n",
       "1680       5.0   3.0   5.0   5.0  \n",
       "1941       5.0   3.0   5.0   1.0  \n",
       "1980       5.0   5.0   5.0   5.0  \n",
       "2063       2.0   5.0   4.0   5.0  \n",
       "2909       5.0   4.0   5.0   5.0  \n",
       "3618       3.0   3.0   4.0   4.0  \n",
       "4169       5.0   4.0   5.0   5.0  \n",
       "4277       5.0   5.0   5.0   5.0  \n",
       "4344       2.0   5.0   5.0   5.0  \n",
       "5795       5.0   1.0   2.0   5.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_preview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('user_id')['rating'].count()\n",
    "    \n",
    "    unique_users = ratings.user_id.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.user_id.map(user_to_index)\n",
    "    \n",
    "    unique_movies = ratings.movie_id.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movie_id.map(movie_to_index)\n",
    "    \n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "    \n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 6040 users, 3706 movies\n",
      "Dataset shape: (1000209, 2)\n",
      "Target shape: (1000209,)\n"
     ]
    }
   ],
   "source": [
    "(n, m), (X, y), _ = create_dataset(df)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsIterator:\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        \n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in ReviewsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3808, 2234],\n",
      "        [1388,  143],\n",
      "        [4509,  849],\n",
      "        [1016, 2393]])\n",
      "tensor([[4.],\n",
      "        [4.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in batches(X, y, bs=4):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    '''\n",
    "    Creates a dense network with embedding layers.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        n_users:            \n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_movies: \n",
    "            Number of unique movies in the dataset.\n",
    "\n",
    "        n_factors: \n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout: \n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of \n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts: \n",
    "            A single integer or a list of integers defining the dropout \n",
    "            layers rates applyied right after each of hidden layers.\n",
    "            \n",
    "    '''\n",
    "    def __init__(self, n_users, n_movies,\n",
    "                 n_factors=50, embedding_dropout=0.02, \n",
    "                 hidden=10, dropouts=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "        \n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and \n",
    "            their activations/dropouts.\n",
    "            \n",
    "            Note that the function captures `hidden` and `dropouts` \n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "            \n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "            \n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self._init()\n",
    "        \n",
    "    def forward(self, users, movies, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "    \n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "        \n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "                \n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "    \n",
    "    \n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNet(\n",
       "  (u): Embedding(6040, 150)\n",
       "  (m): Embedding(3706, 150)\n",
       "  (drop): Dropout(p=0.02, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbeddingNet(n, m, n_factors=150, hidden=100, dropouts=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNet(\n",
       "  (u): Embedding(6040, 150)\n",
       "  (m): Embedding(3706, 150)\n",
       "  (drop): Dropout(p=0.02, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=200, out_features=300, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbeddingNet(n, m, n_factors=150, hidden=[100, 200, 300], dropouts=[0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular(step_size, max_lr, method='triangular', gamma=0.99):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        period = 2 * step_size\n",
    "        cycle = math.floor(1 + epoch/period)\n",
    "        x = abs(epoch/step_size - 2*cycle + 1)\n",
    "        delta = (max_lr - base_lr)*max(0, (1 - x))\n",
    "\n",
    "        if method == 'triangular':\n",
    "            pass  # we've already done\n",
    "        elif method == 'triangular2':\n",
    "            delta /= float(2 ** (cycle - 1))\n",
    "        elif method == 'exp_range':\n",
    "            delta *= (gamma**epoch)\n",
    "        else:\n",
    "            raise ValueError('unexpected method: %s' % method)\n",
    "            \n",
    "        return base_lr + delta\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr(schedule):\n",
    "    ts = list(range(1000))\n",
    "    y = [schedule(t, 0.001) for t in ts]\n",
    "    plt.plot(ts, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 5.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = float(df.rating.min()), float(df.rating.max())\n",
    "minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EmbeddingNet(\n",
    "    n_users=n, n_movies=m, \n",
    "    n_factors=150, hidden=[500, 500, 500], \n",
    "    embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 2000\n",
    "n_epochs = 100\n",
    "patience = 10\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9cfadcf930>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.001\n",
    "        self.test_batch_size = 8\n",
    "        self.batch_size = 8\n",
    "        self.log_interval = 10\n",
    "        self.seed = 1\n",
    "    \n",
    "args = Parser()\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "bob_worker = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice_worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "# kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook}\n",
    "# alice = WebsocketClientWorker(id='alice', port=8779, **kwargs_websocket)\n",
    "# bob = WebsocketClientWorker(id='bob', port=8778, **kwargs_websocket)\n",
    "compute_nodes = [bob_worker, alice_worker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader([X_train, y_train], batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader([X_valid, y_valid], batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'msgpack' has no attribute 'dumps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4765c13f83c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mremote_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, inplace, user, local_autograd, requires_grad, preinitialize_grad, no_wrap, garbage_collect_data, *location)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mpreinitialize_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreinitialize_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                 \u001b[0mgarbage_collect_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgarbage_collect_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             )\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj, workers, ptr_id, garbage_collect_data, requires_grad, create_pointer, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Send the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_obj\u001b[0;34m(self, obj, location)\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0mreceive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObjectMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     def request_obj(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Step 1: serialize the message to a binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mbin_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, worker, simplified, force_full_simplification, strategy)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_full_simplification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/serde/msgpack/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, worker, simplified, force_full_simplification)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0msimple_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_serialize_msgpack_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_full_simplification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_msgpack_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/syft/serde/msgpack/serde.py\u001b[0m in \u001b[0;36m_serialize_msgpack_binary\u001b[0;34m(simple_objects, worker, simplified, force_full_simplification)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# 2) Serialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# serialize into a binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsgpack_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# 3) Compress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'msgpack' has no attribute 'dumps'"
     ]
    }
   ],
   "source": [
    "remote_dataset = (list(), list())\n",
    "train_distributed_dataset = []\n",
    "\n",
    "for batch_idx in range(len(X_train)):\n",
    "    data = torch.tensor([X_train.iloc[0][0], X_train.iloc[0][1]])\n",
    "    target = torch.tensor(y_train.iloc[0])\n",
    "    data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
    "    trainData.append(torch.tensor(data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-1d57365bac5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "y_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f9cb11c51e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/100] train: 0.8866 - val: 0.8221\n",
      "loss improvement on epoch: 2\n",
      "[002/100] train: 0.7963 - val: 0.8066\n",
      "loss improvement on epoch: 3\n",
      "[003/100] train: 0.7998 - val: 0.7984\n",
      "loss improvement on epoch: 4\n",
      "[004/100] train: 0.7582 - val: 0.7860\n",
      "loss improvement on epoch: 5\n",
      "[005/100] train: 0.7663 - val: 0.7852\n",
      "loss improvement on epoch: 6\n",
      "[006/100] train: 0.7287 - val: 0.7833\n",
      "loss improvement on epoch: 7\n",
      "[007/100] train: 0.7414 - val: 0.7829\n",
      "[008/100] train: 0.6943 - val: 0.7888\n",
      "[009/100] train: 0.7071 - val: 0.7854\n",
      "[010/100] train: 0.6498 - val: 0.7985\n",
      "[011/100] train: 0.6659 - val: 0.7933\n",
      "[012/100] train: 0.6101 - val: 0.8085\n",
      "[013/100] train: 0.6311 - val: 0.7984\n",
      "[014/100] train: 0.5787 - val: 0.8139\n",
      "[015/100] train: 0.6025 - val: 0.8100\n",
      "[016/100] train: 0.5540 - val: 0.8249\n",
      "[017/100] train: 0.5798 - val: 0.8197\n",
      "early stopping after epoch 017\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "    \n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "            training = True\n",
    "        else:\n",
    "            training = False\n",
    "\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #print(x_batch[:,0])\n",
    "          \n",
    "        \n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    lr_history.extend(scheduler.get_lr())\n",
    "                    \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        \n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "                \n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.8851\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best.weights', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
